{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5480b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear,Softmax,CrossEntropyLoss,ReLU,Sequential, Module\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from torchvision.models import resnet18, alexnet, vgg11, efficientnet_b0, resnet152\n",
    "from tqdm import tqdm_notebook\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d506d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "label_dict = dict([(j,i) for (i,j) in sorted(list(enumerate(os.listdir('../Dataset/CIFAR-10-images/train/'))))])\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b849c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "label = []\n",
    "for i in os.listdir('../Dataset/CIFAR-10-images/train/'):\n",
    "    for j in os.listdir('../Dataset/CIFAR-10-images/train/'+str(i))[:500]:\n",
    "        paths.append('../Dataset/CIFAR-10-images/train/'+str(i)+'/'+str(j))\n",
    "        label.append(i)\n",
    "train_df = pd.DataFrame({\"paths\": paths, \"label\": label})  \n",
    "\n",
    "paths = []\n",
    "label = []\n",
    "for i in os.listdir('../Dataset/CIFAR-10-images/test/'):\n",
    "    for j in os.listdir('../Dataset/CIFAR-10-images/test/'+str(i))[:500]:\n",
    "        paths.append('../Dataset/CIFAR-10-images/test/'+str(i)+'/'+str(j))\n",
    "        label.append(i)\n",
    "test_df = pd.DataFrame({\"paths\": paths, \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa20dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classes:  10\n",
      "train images:  5000\n",
      "test classes:  10\n",
      "test images:  5000\n"
     ]
    }
   ],
   "source": [
    "print(\"train classes: \", len(train_df['label'].unique()))\n",
    "print(\"train images: \", len(train_df['paths'].unique()))\n",
    "print(\"test classes: \", len(test_df['label'].unique()))\n",
    "print(\"test images: \", len(test_df['paths'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1acc211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARDataSet(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.transform = transform\n",
    "        self.df = csv_file\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        label = label_dict[self.df.iloc[idx]['label']]\n",
    "        label_onehot = np.zeros(10)\n",
    "        label_onehot[label] = 1.\n",
    "        path = self.df.iloc[idx]['paths']\n",
    "        image = Image.open(path)\n",
    "        image = self.transform(image)\n",
    "        sample = {\n",
    "            \"image\": image.to(device),\n",
    "            \"label\": torch.from_numpy(label_onehot).to(device)\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a03e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "#         x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fb9460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c58a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "num_of_epochs = 20\n",
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c77cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = CIFARDataSet(train_df, transform=transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "]))\n",
    "trainloader = DataLoader(traindataset, batch_size=train_batch_size,shuffle=True)\n",
    "valdataset = CIFARDataSet(test_df, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "]))\n",
    "valloader = DataLoader(valdataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "debe9369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1821318",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = CrossEntropyLoss().to(device)\n",
    "optimizer = Adam(params_to_update, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98465a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------starting train loop------------------\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aa8396d0534cf0b8b8d150ef8786f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.3064 total loss: tensor(291.7595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.3064\n",
      "test acc: 0.3102 test f1_score: 0.3102\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc58d8fd61c042ae9ca27ba58583fcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.3486 total loss: tensor(279.8996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.3486\n",
      "test acc: 0.326 test f1_score: 0.326\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c677023273e245d8bee4d16b569dd19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.3762 total loss: tensor(264.5632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.3762\n",
      "test acc: 0.2978 test f1_score: 0.2978\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2415cf48acaa4e8991e4582ad72f2ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.3994 total loss: tensor(257.9651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.3994\n",
      "test acc: 0.3886 test f1_score: 0.3886\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4c699e1c3b4e28ad0370b40530808a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.4242 total loss: tensor(248.2541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.4242\n",
      "test acc: 0.3824 test f1_score: 0.3824\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b4cade0ee446d1a4b47b15ae73c8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.4336 total loss: tensor(242.1555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.43359999999999993\n",
      "test acc: 0.413 test f1_score: 0.413\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1afcf4f42334bbbacd1a68fab0bf046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.4564 total loss: tensor(236.3896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.4564\n",
      "test acc: 0.4362 test f1_score: 0.4362\n",
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a7ce4fbf6f4cb59c88b81a5aad2ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc: 0.4576 total loss: tensor(230.8333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>) training f1_score: 0.4576\n",
      "test acc: 0.3984 test f1_score: 0.3984\n",
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\AppData\\Local\\Temp/ipykernel_22580/2026690136.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(trainloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744ff4b8d1974332b490e219c23f7f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_f1 = []\n",
    "test_f1 = []\n",
    "print(\"----------------starting train loop------------------\")\n",
    "for epoch in range(num_of_epochs):\n",
    "    model.train()\n",
    "    start_time = time()\n",
    "    print(\"epoch:\",epoch)\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm_notebook(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch['image'].to(device))\n",
    "        loss = criterian(output,batch['label'])\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred += list(output.argmax(dim=1).detach().cpu().numpy())\n",
    "        y_true += list(batch['label'].argmax(dim=1).detach().cpu().numpy()) \n",
    "    print(\"training acc:\",accuracy_score(y_pred,y_true),end=' ')\n",
    "    f1 = f1_score(y_pred,y_true, average='micro')\n",
    "    train_f1.append(f1)\n",
    "    print(\"total loss:\", total_loss, end=' ')\n",
    "    print(\"training f1_score:\", f1)\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    for batch in valloader:\n",
    "        output = model(batch['image'].to(device))\n",
    "        y_pred += list(output.argmax(dim=1).detach().cpu().numpy())\n",
    "        y_true += list(batch['label'].argmax(dim=1).detach().cpu().numpy())\n",
    "    print(\"test acc:\",accuracy_score(y_pred,y_true),end=' ')\n",
    "    f1 = f1_score(y_pred,y_true, average='micro')\n",
    "    test_f1.append(f1)\n",
    "    print(\"test f1_score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc365b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
